# **Observability RAG Assistant**  
**AI-powered server monitoring with natural language queries**  

---

## **ğŸš€ Features**  
âœ… **Natural Language Processing** - Ask questions like "Show servers with high CPU"  
âœ… **Dual Interfaces** - CLI for experts & Web UI for visualization  
âœ… **Local Execution** - Runs entirely on your machine (DuckDB + Ollama)  
âœ… **Dark/Light Mode** - Eye-friendly interface with smooth animations  
âœ… **Optimized Performance** - Indexed database + quantized LLMs  

---

## **âš¡ Quick Start**  

### **1. Install Requirements**  
```bash
# Core dependencies
pip install -r requirements.txt

# Download optimized LLM (1.6GB)
ollama pull  llama3.2:1b
```

### **2. Initialize System**  
```bash
# Generate sample telemetry (10 servers, 7 days data)
python data_generator.py

# Setup optimized database
python db_setup.py
```

### **3. Launch Interface**  


 
####  CLI**  
```bash
python cli.py
```

---

## **ğŸ” Sample Queries**  

```sql
"Show top 3 servers by memory usage today"  
"Find hosts with disk >90% in last 6 hours"  
"Compare CPU spikes between 2-4 PM yesterday"  
"Which services had abnormal metrics this week?"
```

---

## **ğŸ› ï¸ Architecture**  

```mermaid
flowchart LR
    A[User Query] --> B[LLM SQL Generator]
    B --> C[DuckDB Engine]
    C --> D[Result Analyzer]
    D --> E{{Formatted Response}}
```

**Key Components:**  
- **RAG Core**: `rag_core.py` (Query processing brain)  
- **Web Interface**: `web_ui.py` (Gradio-powered)  
- **CLI**: `cli.py` (For terminal lovers)  
- **Database**: DuckDB with automatic indexing  

---

**Pro Tip:** For GPU acceleration:  
```python
# In rag_core.py
ChatOllama(model="mistral", num_gpu=1)
```
---

### File Structure
observability-rag
/

â”œâ”€â”€ docs/

â”‚ â”œâ”€â”€ CLI_demo.mp4

â”‚ â”œâ”€â”€ UI_demo.mp4

â”‚ â”œâ”€â”€ cli_thumbnail.png

â”‚ â””â”€â”€ ui_thumbnail.png

â”œâ”€â”€ data_generator.py

â”œâ”€â”€ db_setup.py

â”œâ”€â”€ rag_core.py

â”œâ”€â”€ cli.py

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md


---

## **ğŸš¨ Troubleshooting**  

| Symptom | Solution |
|---------|----------|
| Port 7860 busy | Use `python web_ui.py --port 7861` |
| Slow responses | Try `ollama pull mistral:7b-instruct-q4_K_M` |
| SQL errors | Check `python db_setup.py --reset` |

---

ğŸ’¡ **Pro Tip:** Bookmark [localhost:7860](http://localhost:7860) 

---

**â–¶ï¸ Watch Full Demos:**  
- [CLI Walkthrough](docs/CLI_demo.mp4)  
- [Web UI Tutorial](docs/UI_demo.mp4)  

```
